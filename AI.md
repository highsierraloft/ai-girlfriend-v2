Below is the revised AI.md â€” cleaner, tighter, and 100 % aligned with the spec you just gave.
Copy-paste it into the repo root (or into docs/ if thatâ€™s your convention) and let Cursor do its thing.

â¸»


# AI-Girlfriend Telegram Bot

> **Status:** MVP design phase â€” last updated: 2025-06-20  
> **Owner:** Herman

A Telegram bot that role-plays **Alice** â€” a cheeky, slightly bratty e-girl.  
**Spice8B** (self-hosted on Hugging Face) handles the dialogue; users pay â€œloansâ€ (credits) to keep chatting.  
No embeddings, no vector search â€” we simply feed the model **base-prompt + user-profile + chat history** until we hit the 8 k-token context limit.

---

## âš¡ TL;DR

* **MVP in â‰¤ 2 months**, dockerised, <$10 k CAPEX.  
* **Start pack:** 10 free loans per user, +10 every day at 22:00 Europe/Kyiv.  
* **Credits = messages.** One loan â†’ one reply from the model.  
* Age-gate (18 +) with inline keyboard.  
* PostgreSQL persists everything; Redis caches recent history; APScheduler tops up loans nightly.  
* Payments via **â‚´ / â‚½ / â‚º / crypto** (gateways TBD in Phase 2).  
* Phase 2 also adds erotic image generation & backup censored model.

---

## 1 Â· Project Goals

| KPI | Target |
|-----|--------|
| **Shipping** | MVP live in 8 weeks |
| **Daily Active Users** | â‰¥ 1 000 |
| **Paid Conversion** | â‰¥ 7 % |
| **Variable Cost** | â‰¤ $0.05 / engaged user |
| **Content class** | C2 erotic (no minors, bestiality, gore) |

---

## 2 Â· High-Level Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Telegram   â”‚â—„â”€â”€â”€â”€â”€â”€â–ºâ”‚ Bot Webhook (FastAPI)  â”‚â—„â”€â”€â”€â”€â”€â”€â–ºâ”‚  Redis (cache)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â€¢ python-telegram-bot â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â€¢ Scheduler (APSched) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Spice8B @ HuggingFace â”‚
â”‚  (text generation)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚async-pg
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL (RDS / self)â”‚
â”‚  â€¢ user_profile        â”‚
â”‚  â€¢ message_log         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

_All inference runs on Hugging Face; the bot server is CPU-only._

---

## 3 Â· Tech Stack

| Layer | Choice & Rationale |
|-------|--------------------|
| **Bot Framework** | [`python-telegram-bot v20`](https://docs.python-telegram-bot.org/) (async) |
| **Backend** | `FastAPI` + `uvicorn` |
| **LLM** | **Spice8B** (fork of Llama 2 8B) â€” chat template requires `<|im_start|>` / `<|im_end|>` delimiters  [oai_citation:0â€¡community.openai.com](https://community.openai.com/t/what-do-the-im-start-and-im-end-tokens-mean/145727?utm_source=chatgpt.com) |
| **DB** | PostgreSQL 16 |
| **Cache / Rate-limit** | Redis |
| **Scheduler** | APScheduler |
| **Container** | `python:3.12-slim` â†’ multi-stage docker; app starts with `python -m bot` |
| **Testing** | `pytest` (loan logic, age-gate, token-budget) |
| **Logging** | STDOUT JSON; can be scraped by Loki / Promtail later |
| **Payments** | TBD â€” placeholder handlers for â‚´ MonoPay, â‚½ YooMoney, â‚º PayTR, crypto (UTORG) |

---

## 4 Â· Prompt Strategy

Spice8B follows **ChatML**:

```text
<|im_start|>system
You are Alice, a playful...
<|im_end|>
<|im_start|>user
Hi!
<|im_end|>
<|im_start|>assistant

Prompt budget: 8 000 tokens (Spice8B max context).
	1.	Base prompt â€” persona & style.
	2.	User profile â€” free-text preferences (stored in user_profile.preference).
	3.	Chat history â€” all messages after last_reset_at, newest first, until we hit the limit.
	4.	Assistant prefix (<|im_start|>assistant\n) to get the reply.

Token counting uses the modelâ€™s own tokenizer (loaded once at startup).
If the combined prompt > 8 000 tokens, we truncate the oldest messages.

â¸»

5 Â· Menu & Commands

Command / Button	Action
Profile	Show current profile prefs & allow editing
Loans	Display remaining loans
Top-up	Inline buttons: â‚´ / â‚½ / â‚º / Crypto (opens payment URL)
About	Usage tips (asterisks = actions, plain = dialogue)
Dev Group	Jump to t.me/YourDevGroup
/reset	Sets last_reset_at = NOW; future prompts ignore older history
Age-gate (inline)	â€œIâ€™m 18â€ âœ… unlocks chat, â€œIâ€™m < 18â€ ğŸš« = goodbye


â¸»

6 Â· Credit System (â€œLoansâ€)
	â€¢	Table user_profile.loan_balance (int).
	â€¢	New user â†’ loan_balance = 10.
	â€¢	Each assistant reply decrements by 1.
	â€¢	If zero: bot replies â€œOut of loans â€” top-up or wait for daily refillâ€.
	â€¢	Scheduler job (Europe/Kyiv, 22:00 daily)

UPDATE user_profile SET loan_balance = loan_balance + 10;



â¸»

7 Â· Data Model (minimal)

erDiagram
  user_profile {
    bigint id PK
    bigint chat_id UNIQUE
    timestamptz created_at
    text preference
    int loan_balance
    timestamptz last_reset_at
  }
  message_log {
    bigint id PK
    bigint chat_id FK
    text role  -- 'user' | 'assistant'
    text content
    timestamptz created_at
  }
  user_profile ||--|{ message_log : "has"

Index on message_log.chat_id, created_at for fast fetch.

â¸»

8 Â· Configuration

env file (loaded by Pydantic BaseSettings):

TELEGRAM_TOKEN=...
HF_ENDPOINT=https://api-inference.huggingface.co/models/your-org/spice8b
HF_API_KEY=...
DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/db
REDIS_URL=redis://localhost:6379/0
SCHEDULE_TIMEZONE=Europe/Kyiv
FREE_DAILY_LOANS=10


# --- rate limits ---
RATE_LIMIT_PER_USER_SEC=3        # 1 msg / N seconds
HF_MAX_RPS=5                     # global cap towards Spice8B
SCHEDULE_TIMEZONE=Europe/Kyiv
FREE_DAILY_LOANS=10

All prompts, temperatures etc. live in /app/config/prompts.py so ops can tweak without code edits.

â¸»

9 Â· Setup & Local Dev

# 1. clone fork of python-telegram-bot-base
git clone https://github.com/your-org/ai-girlfriend.git && cd ai-girlfriend

# 2. env vars
cp .env.example .env && nano .env

# 3. start infra
docker compose up -d postgres redis

# 4. run migrations (simple SQL, no Alembic)
psql -f scripts/schema.sql

# 5. launch bot
docker compose up bot

No Alembic: schema changes = new SQL file in scripts/migrations/ executed on deploy.

â¸»

10 Â· Testing

pytest -q

	â€¢	Loan debit / refill
	â€¢	Age-gate lock
	â€¢	Prompt builder respects 8 k tokens
	â€¢	/reset slices history correctly

â¸»

11 Â· Deployment
	â€¢	Container: single image, < 300 MB.
	â€¢	Runtime: any Docker host (Hetzner Cloud / Fly.io / AWS Fargate).
	â€¢	Expose /webhook behind HTTPS (nginx or Cloudflare Tunnel).
	â€¢	Use Telegram â€œself-signed certificateâ€ option if needed.

CI pipeline (GitHub Actions):
	1.	Lint â†’ Unit tests â†’ Build image â†’ Push :latest
	2.	SSH into host, docker pull && docker compose up -d --force-recreate

â¸»

12 Â· Roadmap (Phase 2)

Feature	Notes
Erotic image generation	SDXL LoRA on Replicate; cost paid in loans (10 credits per image)
Backup censored model	Fireworks endpoint; switch via /settings
Voice replies	TTS (Coqui) streamed as OGG
Payment gateways	Implement real SDKs & webhook handlers
Observability	Prometheus + Grafana Cloud, Sentry tracing


â¸»

13 Â· License

MIT â€” you must be â‰¥ 18 y o to use this bot.

â¸»

Reality check: external NSFW APIs can disappear overnight; keep self-host fallback scripts handy.

### How this differs from the previous draft

* Cut embeddings, pgvector, and image generation from the MVP path.  
* Replaced Llama-3 + Fireworks with **Spice8B on Hugging Face** and documented its `<|im_start|>` / `<|im_end|>` chat template.  
* Added **loans** system, daily scheduler top-up, age-gate UX, `/reset` logic, and full message retention in PostgreSQL.  
* Swapped Alembic for plain SQL migrations (simpler).  
* Docker-centric deploy with minimal unit-test harness.  
* Stubbed out payments & Phase-2 roadmap.

Kick the tyres; if somethingâ€™s still off, shout and weâ€™ll tweak.